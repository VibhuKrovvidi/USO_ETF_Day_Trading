{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import statsmodels.api as sm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/master_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_selection(data, response_col, alpha=0.05):\n",
    "    selected_features = []\n",
    "    remaining_features = list(data.columns.drop(response_col))\n",
    "\n",
    "    while remaining_features:\n",
    "        best_pvalue = float('inf')\n",
    "        best_feature = None\n",
    "\n",
    "        for feature in remaining_features:\n",
    "            X = data[selected_features + [feature]]\n",
    "            X = sm.add_constant(X)  # Add a constant term for the intercept\n",
    "            y = data[response_col]\n",
    "\n",
    "            model = sm.OLS(y, X).fit()\n",
    "            pvalue = model.pvalues[feature]\n",
    "\n",
    "            if pvalue < best_pvalue:\n",
    "                best_pvalue = pvalue\n",
    "                best_feature = feature\n",
    "\n",
    "        if best_pvalue < alpha:\n",
    "            selected_features.append(best_feature)\n",
    "            remaining_features.remove(best_feature)\n",
    "            print(f\"Added {best_feature} with p-value {best_pvalue:.4f}\")\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, y_var_name=\"High\", regressor = RandomForestRegressor(), param_dist = None ):\n",
    "    # Break into x and y\n",
    "    X = df.drop(y_var_name, axis=1)\n",
    "    y_archive = df[y_var_name]\n",
    "    y = df[y_var_name] - df[\"Open\"]\n",
    "    y = pd.DataFrame(y)\n",
    "\n",
    "    numeric_cols = X.select_dtypes(include=[np.number]).columns\n",
    "    X = X[numeric_cols]\n",
    "\n",
    "    # Avoid leakage\n",
    "    drop_mask = []\n",
    "\n",
    "    for col in X:\n",
    "        if 'high' in str(col).lower():\n",
    "            \n",
    "            if 'lag' in str(col).lower():\n",
    "                pass\n",
    "            else:\n",
    "                print(col)\n",
    "                drop_mask.append(col)\n",
    "        if 'low' in str(col).lower():\n",
    "            \n",
    "            if 'lag' in str(col).lower():\n",
    "                pass\n",
    "            else:\n",
    "                print(col)\n",
    "                drop_mask.append(col)\n",
    "\n",
    "        if 'close' in str(col).lower():\n",
    "            \n",
    "            if 'lag' in str(col).lower():\n",
    "                pass\n",
    "            else:\n",
    "                print(col)\n",
    "                drop_mask.append(col)\n",
    "\n",
    "    # Drop elems in drop mask\n",
    "    X = X.drop(drop_mask, axis=1)\n",
    "    X.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "\n",
    "    X_dev, X_test, y_dev, y_test = train_test_split(X, y, test_size=0.25, random_state=3)\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_dev, y_dev, test_size = 0.25)\n",
    "\n",
    "    # Variable Selection\n",
    "    data_x = pd.DataFrame(X, columns=X.columns)\n",
    "    data_y = pd.DataFrame(y, columns=[y_var_name])\n",
    "    data = data_x.copy()\n",
    "    data[y_var_name] = data_y\n",
    "    data\n",
    "    \n",
    "    # Perform forward variable selection\n",
    "    response_column = y_var_name\n",
    "    selected_features = forward_selection(data, response_column)\n",
    "\n",
    "    # print(\"Starting Columns:\" , len(data.columns)-1)\n",
    "    # print(\"Final Columns:\" , len(selected_features))\n",
    "    # Print the selected features\n",
    "    # print(\"Selected Features:\", selected_features)\n",
    "\n",
    "    numerical_features = X_train.columns\n",
    "\n",
    "    # Create a ColumnTransformer to apply scaling to numerical features\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', MinMaxScaler(), numerical_features)\n",
    "        ])\n",
    "\n",
    "    # Instantiate the XGBoost regressor\n",
    "    # xg_reg = xgb.XGBRegressor()\n",
    "\n",
    "    # Create the pipeline with preprocessing and XGBoost\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', regressor)\n",
    "    ])\n",
    "\n",
    "    # Instantiate RandomizedSearchCV\n",
    "    random_search = RandomizedSearchCV(pipeline, param_distributions=param_dist, n_iter=20, scoring='neg_mean_squared_error', cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "    # Fit the random search to the data\n",
    "    random_search.fit(X_train, y_train)\n",
    "\n",
    "    # Print the best hyperparameters\n",
    "    print(\"Best Hyperparameters:\", random_search.best_params_)\n",
    "\n",
    "    # Predict on the test set using the best model\n",
    "    y_pred = random_search.best_estimator_.predict(X_val)\n",
    "\n",
    "    # Evaluate the model\n",
    "    mse = mean_squared_error(y_val, y_pred)\n",
    "    print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "    dataframes = {'X_train' : X_train,'X_val' : X_val,'X_test' : X_test,'y_train' : y_train,'y_val' : y_val,'y_test' : y_test}\n",
    "    predictions = y_pred\n",
    "\n",
    "    return random_search.best_estimator_, predictions, dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low\n",
      "Close\n",
      "Adj Close\n",
      "High_DXY\n",
      "Low_DXY\n",
      "Close_DXY\n",
      "Adj Close_DXY\n",
      "High_CHF\n",
      "Low_CHF\n",
      "High_BNO\n",
      "Low_BNO\n",
      "Close_BNO\n",
      "Adj Close_BNO\n",
      "High_GSCI\n",
      "Low_GSCI\n",
      "High_USL\n",
      "Low_USL\n",
      "Close_USL\n",
      "Adj Close_USL\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Prahlad\\Documents\\Columbia\\Coursework\\Financing and Structuring for Data Science\\Project\\USO_ETF_Day_Trading\\uso_etf_venv\\Lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'regressor__n_estimators': 150, 'regressor__min_samples_split': 10, 'regressor__min_samples_leaf': 2, 'regressor__max_features': 'sqrt', 'regressor__max_depth': None}\n",
      "Mean Squared Error: 10.073836585810072\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for random search\n",
    "param_dist = {\n",
    "    'regressor__n_estimators': [50, 100, 150, 200],\n",
    "    'regressor__max_depth': [None, 10, 20, 30],\n",
    "    'regressor__min_samples_split': [2, 5, 10],\n",
    "    'regressor__min_samples_leaf': [1, 2, 4],\n",
    "    'regressor__max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "best_model, high_delta_pred, df_list = preprocess(df, \"High\", param_dist=param_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High\n",
      "Close\n",
      "Adj Close\n",
      "High_DXY\n",
      "Low_DXY\n",
      "Close_DXY\n",
      "Adj Close_DXY\n",
      "High_CHF\n",
      "Low_CHF\n",
      "High_BNO\n",
      "Low_BNO\n",
      "Close_BNO\n",
      "Adj Close_BNO\n",
      "High_GSCI\n",
      "Low_GSCI\n",
      "High_USL\n",
      "Low_USL\n",
      "Close_USL\n",
      "Adj Close_USL\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Prahlad\\Documents\\Columbia\\Coursework\\Financing and Structuring for Data Science\\Project\\USO_ETF_Day_Trading\\uso_etf_venv\\Lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'regressor__n_estimators': 200, 'regressor__min_samples_split': 10, 'regressor__min_samples_leaf': 1, 'regressor__max_features': 'log2', 'regressor__max_depth': 20}\n",
      "Mean Squared Error: 9.170739320479084\n"
     ]
    }
   ],
   "source": [
    "best_model_low, low_delta_pred, df_list = preprocess(df, \"Low\", param_dist=param_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = df[df.index.isin(df_list[\"X_train\"].index)]\n",
    "data_val = df[df.index.isin(df_list[\"X_val\"].index)]\n",
    "data_test = df[df.index.isin(df_list[\"X_test\"].index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>T10Y2Y_Ten_Two</th>\n",
       "      <th>Date_lag_Ten_Two</th>\n",
       "      <th>...</th>\n",
       "      <th>Close_USL</th>\n",
       "      <th>Adj Close_USL</th>\n",
       "      <th>Volume_USL</th>\n",
       "      <th>Date_lag_USL</th>\n",
       "      <th>Open_lag_USL</th>\n",
       "      <th>High_lag_USL</th>\n",
       "      <th>Low_lag_USL</th>\n",
       "      <th>Close_lag_USL</th>\n",
       "      <th>Adj Close_lag_USL</th>\n",
       "      <th>Volume_lag_USL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2006-04-12 00:00:00</td>\n",
       "      <td>545.760010</td>\n",
       "      <td>550.479980</td>\n",
       "      <td>542.479980</td>\n",
       "      <td>542.719971</td>\n",
       "      <td>542.719971</td>\n",
       "      <td>156038</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1 days 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2006-04-13 00:00:00</td>\n",
       "      <td>540.000000</td>\n",
       "      <td>551.919983</td>\n",
       "      <td>539.200012</td>\n",
       "      <td>550.559998</td>\n",
       "      <td>550.559998</td>\n",
       "      <td>70088</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1 days 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2006-04-17 00:00:00</td>\n",
       "      <td>553.599976</td>\n",
       "      <td>559.200012</td>\n",
       "      <td>549.440002</td>\n",
       "      <td>558.320007</td>\n",
       "      <td>558.320007</td>\n",
       "      <td>114713</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1 days 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2006-04-21 00:00:00</td>\n",
       "      <td>567.119995</td>\n",
       "      <td>585.840027</td>\n",
       "      <td>566.400024</td>\n",
       "      <td>582.479980</td>\n",
       "      <td>582.479980</td>\n",
       "      <td>133225</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1 days 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2006-04-24 00:00:00</td>\n",
       "      <td>571.200012</td>\n",
       "      <td>579.599976</td>\n",
       "      <td>566.320007</td>\n",
       "      <td>568.080017</td>\n",
       "      <td>568.080017</td>\n",
       "      <td>130288</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1 days 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4407</th>\n",
       "      <td>4407</td>\n",
       "      <td>2023-10-12 00:00:00</td>\n",
       "      <td>76.580002</td>\n",
       "      <td>76.610001</td>\n",
       "      <td>74.620003</td>\n",
       "      <td>75.419998</td>\n",
       "      <td>75.419998</td>\n",
       "      <td>4244100</td>\n",
       "      <td>-0.36</td>\n",
       "      <td>1 days 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>38.099998</td>\n",
       "      <td>38.099998</td>\n",
       "      <td>18000.0</td>\n",
       "      <td>1 days 00:00:00</td>\n",
       "      <td>-0.340000</td>\n",
       "      <td>-0.200001</td>\n",
       "      <td>-0.529999</td>\n",
       "      <td>-0.190003</td>\n",
       "      <td>-0.190003</td>\n",
       "      <td>6700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4408</th>\n",
       "      <td>4408</td>\n",
       "      <td>2023-10-13 00:00:00</td>\n",
       "      <td>77.709999</td>\n",
       "      <td>79.180000</td>\n",
       "      <td>77.160004</td>\n",
       "      <td>78.989998</td>\n",
       "      <td>78.989998</td>\n",
       "      <td>6765100</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>1 days 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>39.680000</td>\n",
       "      <td>39.680000</td>\n",
       "      <td>19600.0</td>\n",
       "      <td>1 days 00:00:00</td>\n",
       "      <td>0.239998</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.110001</td>\n",
       "      <td>-0.160000</td>\n",
       "      <td>-0.160000</td>\n",
       "      <td>-2800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4409</th>\n",
       "      <td>4409</td>\n",
       "      <td>2023-10-16 00:00:00</td>\n",
       "      <td>78.629997</td>\n",
       "      <td>78.889999</td>\n",
       "      <td>77.870003</td>\n",
       "      <td>78.389999</td>\n",
       "      <td>78.389999</td>\n",
       "      <td>5156200</td>\n",
       "      <td>-0.38</td>\n",
       "      <td>1 days 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>39.540001</td>\n",
       "      <td>39.540001</td>\n",
       "      <td>29600.0</td>\n",
       "      <td>1 days 00:00:00</td>\n",
       "      <td>0.639999</td>\n",
       "      <td>1.169998</td>\n",
       "      <td>1.169998</td>\n",
       "      <td>1.580002</td>\n",
       "      <td>1.580002</td>\n",
       "      <td>1600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4412</th>\n",
       "      <td>4412</td>\n",
       "      <td>2023-10-19 00:00:00</td>\n",
       "      <td>79.370003</td>\n",
       "      <td>81.750000</td>\n",
       "      <td>78.940002</td>\n",
       "      <td>81.680000</td>\n",
       "      <td>81.680000</td>\n",
       "      <td>5924400</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>1 days 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>40.799999</td>\n",
       "      <td>40.799999</td>\n",
       "      <td>4300.0</td>\n",
       "      <td>1 days 00:00:00</td>\n",
       "      <td>0.689998</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>0.880002</td>\n",
       "      <td>0.480004</td>\n",
       "      <td>0.480004</td>\n",
       "      <td>17200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4418</th>\n",
       "      <td>4418</td>\n",
       "      <td>2023-10-27 00:00:00</td>\n",
       "      <td>77.620003</td>\n",
       "      <td>78.980003</td>\n",
       "      <td>76.580002</td>\n",
       "      <td>78.360001</td>\n",
       "      <td>78.360001</td>\n",
       "      <td>5517700</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>1 days 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>39.660000</td>\n",
       "      <td>39.660000</td>\n",
       "      <td>22000.0</td>\n",
       "      <td>1 days 00:00:00</td>\n",
       "      <td>-0.060001</td>\n",
       "      <td>-0.520001</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>-0.689999</td>\n",
       "      <td>-0.689999</td>\n",
       "      <td>7700.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2485 rows Ã— 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                 Date        Open        High         Low  \\\n",
       "2              2  2006-04-12 00:00:00  545.760010  550.479980  542.479980   \n",
       "3              3  2006-04-13 00:00:00  540.000000  551.919983  539.200012   \n",
       "4              4  2006-04-17 00:00:00  553.599976  559.200012  549.440002   \n",
       "8              8  2006-04-21 00:00:00  567.119995  585.840027  566.400024   \n",
       "9              9  2006-04-24 00:00:00  571.200012  579.599976  566.320007   \n",
       "...          ...                  ...         ...         ...         ...   \n",
       "4407        4407  2023-10-12 00:00:00   76.580002   76.610001   74.620003   \n",
       "4408        4408  2023-10-13 00:00:00   77.709999   79.180000   77.160004   \n",
       "4409        4409  2023-10-16 00:00:00   78.629997   78.889999   77.870003   \n",
       "4412        4412  2023-10-19 00:00:00   79.370003   81.750000   78.940002   \n",
       "4418        4418  2023-10-27 00:00:00   77.620003   78.980003   76.580002   \n",
       "\n",
       "           Close   Adj Close   Volume T10Y2Y_Ten_Two Date_lag_Ten_Two  ...  \\\n",
       "2     542.719971  542.719971   156038           0.07  1 days 00:00:00  ...   \n",
       "3     550.559998  550.559998    70088           0.09  1 days 00:00:00  ...   \n",
       "4     558.320007  558.320007   114713            0.1  1 days 00:00:00  ...   \n",
       "8     582.479980  582.479980   133225           0.11  1 days 00:00:00  ...   \n",
       "9     568.080017  568.080017   130288            0.1  1 days 00:00:00  ...   \n",
       "...          ...         ...      ...            ...              ...  ...   \n",
       "4407   75.419998   75.419998  4244100          -0.36  1 days 00:00:00  ...   \n",
       "4408   78.989998   78.989998  6765100          -0.41  1 days 00:00:00  ...   \n",
       "4409   78.389999   78.389999  5156200          -0.38  1 days 00:00:00  ...   \n",
       "4412   81.680000   81.680000  5924400          -0.16  1 days 00:00:00  ...   \n",
       "4418   78.360001   78.360001  5517700          -0.15  1 days 00:00:00  ...   \n",
       "\n",
       "      Close_USL  Adj Close_USL  Volume_USL     Date_lag_USL  Open_lag_USL  \\\n",
       "2      0.000000       0.000000         0.0                0      0.000000   \n",
       "3      0.000000       0.000000         0.0                0      0.000000   \n",
       "4      0.000000       0.000000         0.0                0      0.000000   \n",
       "8      0.000000       0.000000         0.0                0      0.000000   \n",
       "9      0.000000       0.000000         0.0                0      0.000000   \n",
       "...         ...            ...         ...              ...           ...   \n",
       "4407  38.099998      38.099998     18000.0  1 days 00:00:00     -0.340000   \n",
       "4408  39.680000      39.680000     19600.0  1 days 00:00:00      0.239998   \n",
       "4409  39.540001      39.540001     29600.0  1 days 00:00:00      0.639999   \n",
       "4412  40.799999      40.799999      4300.0  1 days 00:00:00      0.689998   \n",
       "4418  39.660000      39.660000     22000.0  1 days 00:00:00     -0.060001   \n",
       "\n",
       "      High_lag_USL Low_lag_USL  Close_lag_USL  Adj Close_lag_USL  \\\n",
       "2         0.000000    0.000000       0.000000           0.000000   \n",
       "3         0.000000    0.000000       0.000000           0.000000   \n",
       "4         0.000000    0.000000       0.000000           0.000000   \n",
       "8         0.000000    0.000000       0.000000           0.000000   \n",
       "9         0.000000    0.000000       0.000000           0.000000   \n",
       "...            ...         ...            ...                ...   \n",
       "4407     -0.200001   -0.529999      -0.190003          -0.190003   \n",
       "4408      0.160000    0.110001      -0.160000          -0.160000   \n",
       "4409      1.169998    1.169998       1.580002           1.580002   \n",
       "4412      0.590000    0.880002       0.480004           0.480004   \n",
       "4418     -0.520001    0.410000      -0.689999          -0.689999   \n",
       "\n",
       "      Volume_lag_USL  \n",
       "2                0.0  \n",
       "3                0.0  \n",
       "4                0.0  \n",
       "8                0.0  \n",
       "9                0.0  \n",
       "...              ...  \n",
       "4407          6700.0  \n",
       "4408         -2800.0  \n",
       "4409          1600.0  \n",
       "4412         17200.0  \n",
       "4418          7700.0  \n",
       "\n",
       "[2485 rows x 76 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prahlad\\AppData\\Local\\Temp\\ipykernel_3004\\1169210767.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_train[\"pred_high_open\"] = best_model.predict(df_list[\"X_train\"])\n",
      "C:\\Users\\Prahlad\\AppData\\Local\\Temp\\ipykernel_3004\\1169210767.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_train[\"actual_high_open\"] = data_train[\"High\"] - data_train[\"Open\"]\n",
      "C:\\Users\\Prahlad\\AppData\\Local\\Temp\\ipykernel_3004\\1169210767.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_train[\"pred_low_open\"] = best_model_low.predict(df_list[\"X_train\"])\n",
      "C:\\Users\\Prahlad\\AppData\\Local\\Temp\\ipykernel_3004\\1169210767.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_train[\"actual_low_open\"] = data_train[\"Low\"] - data_train[\"Open\"]\n",
      "C:\\Users\\Prahlad\\AppData\\Local\\Temp\\ipykernel_3004\\1169210767.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_val[\"pred_high_open\"] = best_model.predict(df_list[\"X_val\"])\n",
      "C:\\Users\\Prahlad\\AppData\\Local\\Temp\\ipykernel_3004\\1169210767.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_val[\"actual_high_open\"] = data_val[\"High\"] - data_val[\"Open\"]\n",
      "C:\\Users\\Prahlad\\AppData\\Local\\Temp\\ipykernel_3004\\1169210767.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_val[\"pred_low_open\"] = best_model_low.predict(df_list[\"X_val\"])\n",
      "C:\\Users\\Prahlad\\AppData\\Local\\Temp\\ipykernel_3004\\1169210767.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_val[\"actual_low_open\"] = data_val[\"Low\"] - data_val[\"Open\"]\n",
      "C:\\Users\\Prahlad\\AppData\\Local\\Temp\\ipykernel_3004\\1169210767.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_test[\"pred_high_open\"] = best_model.predict(df_list[\"X_test\"])\n",
      "C:\\Users\\Prahlad\\AppData\\Local\\Temp\\ipykernel_3004\\1169210767.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_test[\"actual_high_open\"] = data_test[\"High\"] - data_test[\"Open\"]\n",
      "C:\\Users\\Prahlad\\AppData\\Local\\Temp\\ipykernel_3004\\1169210767.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_test[\"pred_low_open\"] = best_model_low.predict(df_list[\"X_test\"])\n",
      "C:\\Users\\Prahlad\\AppData\\Local\\Temp\\ipykernel_3004\\1169210767.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_test[\"actual_low_open\"] = data_test[\"Low\"] - data_test[\"Open\"]\n"
     ]
    }
   ],
   "source": [
    "data_train[\"pred_high_open\"] = best_model.predict(df_list[\"X_train\"])\n",
    "data_train[\"actual_high_open\"] = data_train[\"High\"] - data_train[\"Open\"]\n",
    "data_train[\"pred_low_open\"] = best_model_low.predict(df_list[\"X_train\"])\n",
    "data_train[\"actual_low_open\"] = data_train[\"Low\"] - data_train[\"Open\"]\n",
    "\n",
    "\n",
    "data_val[\"pred_high_open\"] = best_model.predict(df_list[\"X_val\"])\n",
    "data_val[\"actual_high_open\"] = data_val[\"High\"] - data_val[\"Open\"]\n",
    "data_val[\"pred_low_open\"] = best_model_low.predict(df_list[\"X_val\"])\n",
    "data_val[\"actual_low_open\"] = data_val[\"Low\"] - data_val[\"Open\"]\n",
    "\n",
    "data_test[\"pred_high_open\"] = best_model.predict(df_list[\"X_test\"])\n",
    "data_test[\"actual_high_open\"] = data_test[\"High\"] - data_test[\"Open\"]\n",
    "data_test[\"pred_low_open\"] = best_model_low.predict(df_list[\"X_test\"])\n",
    "data_test[\"actual_low_open\"] = data_test[\"Low\"] - data_test[\"Open\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.to_csv('../data/data_train.csv')\n",
    "data_val.to_csv('../data/data_val.csv')\n",
    "data_test.to_csv('../data/data_test.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uso_etf_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
