{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import statsmodels.api as sm\n",
    "import xgboost as xgb\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from scipy.stats import randint\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the master dataset with augmented columns and engineered features\n",
    "df = pd.read_csv(\"../data/master_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_selection(data, response_col, alpha=0.05):\n",
    "    selected_features = []\n",
    "    remaining_features = list(data.columns.drop(response_col))\n",
    "\n",
    "    while remaining_features:\n",
    "        best_pvalue = float('inf')\n",
    "        best_feature = None\n",
    "\n",
    "        for feature in remaining_features:\n",
    "            X = data[selected_features + [feature]]\n",
    "            X = sm.add_constant(X)  # Add a constant term for the intercept\n",
    "            y = data[response_col]\n",
    "\n",
    "            model = sm.OLS(y, X).fit()\n",
    "            pvalue = model.pvalues[feature]\n",
    "\n",
    "            if pvalue < best_pvalue:\n",
    "                best_pvalue = pvalue\n",
    "                best_feature = feature\n",
    "\n",
    "        if best_pvalue < alpha:\n",
    "            selected_features.append(best_feature)\n",
    "            remaining_features.remove(best_feature)\n",
    "            print(f\"Added {best_feature} with p-value {best_pvalue:.4f}\")\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_predict(df, y_var_name=\"High\", regressor = RandomForestRegressor(random_state=42), param_dist = None ):\n",
    "    # Break into x and y\n",
    "    X = df.drop(y_var_name, axis=1)\n",
    "\n",
    "    # Predicts the change (delta) from the Open: for instance High - Open\n",
    "    y = df[y_var_name] - df[\"Open\"]\n",
    "    y = pd.DataFrame(y)\n",
    "\n",
    "    numeric_cols = X.select_dtypes(include=[np.number]).columns\n",
    "    X = X[numeric_cols]\n",
    "\n",
    "    # Avoid leakage\n",
    "    drop_mask = []\n",
    "\n",
    "    for col in X:\n",
    "        if 'high' in str(col).lower():\n",
    "            \n",
    "            if 'lag' in str(col).lower():\n",
    "                pass\n",
    "            else:\n",
    "                print(col)\n",
    "                drop_mask.append(col)\n",
    "        if 'low' in str(col).lower():\n",
    "            \n",
    "            if 'lag' in str(col).lower():\n",
    "                pass\n",
    "            else:\n",
    "                print(col)\n",
    "                drop_mask.append(col)\n",
    "\n",
    "        if 'close' in str(col).lower():\n",
    "            \n",
    "            if 'lag' in str(col).lower():\n",
    "                pass\n",
    "            else:\n",
    "                print(col)\n",
    "                drop_mask.append(col)\n",
    "\n",
    "    # Drop elems in drop mask\n",
    "    X = X.drop(drop_mask, axis=1)\n",
    "    X.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "\n",
    "    X_dev, X_test, y_dev, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_dev, y_dev, test_size = 0.25, random_state=42)\n",
    "\n",
    "    # Variable Selection\n",
    "    data_x = pd.DataFrame(X, columns=X.columns)\n",
    "    data_y = pd.DataFrame(y, columns=[y_var_name])\n",
    "    data = data_x.copy()\n",
    "    data[y_var_name] = data_y\n",
    "    data\n",
    "    \n",
    "    # Perform forward variable selection\n",
    "    response_column = y_var_name\n",
    "    selected_features = forward_selection(data, response_column)\n",
    "\n",
    "    # Create a ColumnTransformer to apply scaling to numerical features\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', MinMaxScaler(), X.columns)\n",
    "        ])\n",
    "\n",
    "    # Create the pipeline with preprocessing and XGBoost\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', regressor)\n",
    "    ])\n",
    "\n",
    "    # Instantiate RandomizedSearchCV\n",
    "    random_search = RandomizedSearchCV(pipeline, param_distributions=param_dist, n_iter=20, scoring='neg_mean_squared_error', cv=5, verbose=1, n_jobs=-1, random_state=42)\n",
    "\n",
    "    # Fit the random search to the data\n",
    "    random_search.fit(X_train, y_train)\n",
    "\n",
    "    # Print the best hyperparameters\n",
    "    print(\"Best Hyperparameters:\", random_search.best_params_)\n",
    "\n",
    "    # Predict on the test set using the best model\n",
    "    y_pred = random_search.best_estimator_.predict(X_val)\n",
    "\n",
    "    # Evaluate the model with the Mean Squared Error and R2 error\n",
    "    mse = mean_squared_error(y_val, y_pred)\n",
    "    print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "    r2 = r2_score(y_val, y_pred)\n",
    "    print(f\"R2 score: {r2}\")\n",
    "\n",
    "    # Also predict on the train dataset to get metrics on train data as well\n",
    "    y_pred_train = random_search.best_estimator_.predict(X_train)\n",
    "\n",
    "    # Evaluate the model with the Mean Squared Error and R2 error for train data\n",
    "    mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "    print(f'Train Mean Squared Error: {mse_train}')\n",
    "\n",
    "    r2_train = r2_score(y_train, y_pred_train)\n",
    "    print(f\"Train R2 score: {r2_train}\")\n",
    "\n",
    "    dataframes = {'X_train' : X_train,'X_val' : X_val,'X_test' : X_test,'y_train' : y_train,'y_val' : y_val,'y_test' : y_test}\n",
    "    predictions = y_pred\n",
    "\n",
    "    return random_search.best_estimator_, predictions, dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment #1: Linear Regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low\n",
      "Close\n",
      "Adj Close\n",
      "High_DXY\n",
      "Low_DXY\n",
      "Close_DXY\n",
      "Adj Close_DXY\n",
      "High_CHF\n",
      "Low_CHF\n",
      "High_BNO\n",
      "Low_BNO\n",
      "Close_BNO\n",
      "Adj Close_BNO\n",
      "High_GSCI\n",
      "Low_GSCI\n",
      "High_USL\n",
      "Low_USL\n",
      "Close_USL\n",
      "Adj Close_USL\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Prahlad\\Documents\\Columbia\\Coursework\\Financing and Structuring for Data Science\\Project\\USO_ETF_Day_Trading\\uso_etf_venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:307: UserWarning: The total space of parameters 4 is smaller than n_iter=20. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'regressor__positive': False, 'regressor__fit_intercept': False}\n",
      "Mean Squared Error: 7.841955270602665\n",
      "R2 score: 0.380188887026385\n",
      "Train Mean Squared Error: 7.677822204467188\n",
      "Train R2 score: 0.5055896763242659\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for random search\n",
    "\n",
    "param_dist = {\n",
    "    'regressor__fit_intercept': [True, False],\n",
    "    'regressor__positive': [True, False],\n",
    "}\n",
    "\n",
    "best_model_lr, high_delta_pred_lr, df_list_lr = preprocess_and_predict(df, \"High\", regressor=LinearRegression(), param_dist=param_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High\n",
      "Close\n",
      "Adj Close\n",
      "High_DXY\n",
      "Low_DXY\n",
      "Close_DXY\n",
      "Adj Close_DXY\n",
      "High_CHF\n",
      "Low_CHF\n",
      "High_BNO\n",
      "Low_BNO\n",
      "Close_BNO\n",
      "Adj Close_BNO\n",
      "High_GSCI\n",
      "Low_GSCI\n",
      "High_USL\n",
      "Low_USL\n",
      "Close_USL\n",
      "Adj Close_USL\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best Hyperparameters: {'regressor__positive': False, 'regressor__fit_intercept': False}\n",
      "Mean Squared Error: 7.934293865890573\n",
      "R2 score: 0.5006839908726448\n",
      "Train Mean Squared Error: 8.260819916765513\n",
      "Train R2 score: 0.5416021013395058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Prahlad\\Documents\\Columbia\\Coursework\\Financing and Structuring for Data Science\\Project\\USO_ETF_Day_Trading\\uso_etf_venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:307: UserWarning: The total space of parameters 4 is smaller than n_iter=20. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "best_model_low_lr, low_delta_pred_lr, df_list_lr = preprocess_and_predict(df, \"Low\", regressor=LinearRegression(), param_dist=param_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment #2: Random Forest Regressors (default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low\n",
      "Close\n",
      "Adj Close\n",
      "High_DXY\n",
      "Low_DXY\n",
      "Close_DXY\n",
      "Adj Close_DXY\n",
      "High_CHF\n",
      "Low_CHF\n",
      "High_BNO\n",
      "Low_BNO\n",
      "Close_BNO\n",
      "Adj Close_BNO\n",
      "High_GSCI\n",
      "Low_GSCI\n",
      "High_USL\n",
      "Low_USL\n",
      "Close_USL\n",
      "Adj Close_USL\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Prahlad\\Documents\\Columbia\\Coursework\\Financing and Structuring for Data Science\\Project\\USO_ETF_Day_Trading\\uso_etf_venv\\Lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'regressor__n_estimators': 200, 'regressor__min_samples_split': 2, 'regressor__min_samples_leaf': 4, 'regressor__max_features': 'log2', 'regressor__max_depth': 30}\n",
      "Mean Squared Error: 8.372897300726871\n",
      "R2 score: 0.338224382096167\n",
      "Train Mean Squared Error: 4.395697441174484\n",
      "Train R2 score: 0.7169408021187058\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for random search\n",
    "param_dist = {\n",
    "    'regressor__n_estimators': [50, 100, 150, 200],\n",
    "    'regressor__max_depth': [None, 10, 20, 30],\n",
    "    'regressor__min_samples_split': [2, 5, 10],\n",
    "    'regressor__min_samples_leaf': [1, 2, 4],\n",
    "    'regressor__max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "best_model_rf, high_delta_pred_rf, df_list_rf = preprocess_and_predict(df, \"High\", param_dist=param_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High\n",
      "Close\n",
      "Adj Close\n",
      "High_DXY\n",
      "Low_DXY\n",
      "Close_DXY\n",
      "Adj Close_DXY\n",
      "High_CHF\n",
      "Low_CHF\n",
      "High_BNO\n",
      "Low_BNO\n",
      "Close_BNO\n",
      "Adj Close_BNO\n",
      "High_GSCI\n",
      "Low_GSCI\n",
      "High_USL\n",
      "Low_USL\n",
      "Close_USL\n",
      "Adj Close_USL\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Prahlad\\Documents\\Columbia\\Coursework\\Financing and Structuring for Data Science\\Project\\USO_ETF_Day_Trading\\uso_etf_venv\\Lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'regressor__n_estimators': 50, 'regressor__min_samples_split': 10, 'regressor__min_samples_leaf': 1, 'regressor__max_features': 'sqrt', 'regressor__max_depth': 30}\n",
      "Mean Squared Error: 8.717670565791952\n",
      "R2 score: 0.4513850193384956\n",
      "Train Mean Squared Error: 3.4808703734837128\n",
      "Train R2 score: 0.80684439549685\n"
     ]
    }
   ],
   "source": [
    "best_model_low_rf, low_delta_pred_rf, df_list_rf = preprocess_and_predict(df, \"Low\", param_dist=param_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment #3: XGBoost Regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low\n",
      "Close\n",
      "Adj Close\n",
      "High_DXY\n",
      "Low_DXY\n",
      "Close_DXY\n",
      "Adj Close_DXY\n",
      "High_CHF\n",
      "Low_CHF\n",
      "High_BNO\n",
      "Low_BNO\n",
      "Close_BNO\n",
      "Adj Close_BNO\n",
      "High_GSCI\n",
      "Low_GSCI\n",
      "High_USL\n",
      "Low_USL\n",
      "Close_USL\n",
      "Adj Close_USL\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Prahlad\\Documents\\Columbia\\Coursework\\Financing and Structuring for Data Science\\Project\\USO_ETF_Day_Trading\\uso_etf_venv\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [17:22:22] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'regressor__n_estimators': 50, 'regressor__min_samples_split': 10, 'regressor__min_samples_leaf': 1, 'regressor__max_features': 'log2', 'regressor__max_depth': 10}\n",
      "Mean Squared Error: 10.410101574510882\n",
      "R2 score: 0.17720818081507572\n",
      "Train Mean Squared Error: 0.001357334901714871\n",
      "Train R2 score: 0.9999125949559365\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for random search\n",
    "param_dist = {\n",
    "    'regressor__n_estimators': [50, 100, 150, 200],\n",
    "    'regressor__max_depth': [None, 10, 20, 30],\n",
    "    'regressor__min_samples_split': [2, 5, 10],\n",
    "    'regressor__min_samples_leaf': [1, 2, 4],\n",
    "    'regressor__max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "best_model_xg, high_delta_pred_xg, df_list_xg = preprocess_and_predict(df, \"High\", regressor=xgb.XGBRegressor(), param_dist=param_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High\n",
      "Close\n",
      "Adj Close\n",
      "High_DXY\n",
      "Low_DXY\n",
      "Close_DXY\n",
      "Adj Close_DXY\n",
      "High_CHF\n",
      "Low_CHF\n",
      "High_BNO\n",
      "Low_BNO\n",
      "Close_BNO\n",
      "Adj Close_BNO\n",
      "High_GSCI\n",
      "Low_GSCI\n",
      "High_USL\n",
      "Low_USL\n",
      "Close_USL\n",
      "Adj Close_USL\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Best Hyperparameters: {'regressor__n_estimators': 50, 'regressor__min_samples_split': 10, 'regressor__min_samples_leaf': 2, 'regressor__max_features': 'log2', 'regressor__max_depth': None}\n",
      "Mean Squared Error: 8.402875761069414\n",
      "R2 score: 0.4711954887066403\n",
      "Train Mean Squared Error: 0.3545757246020291\n",
      "Train R2 score: 0.9803243783654307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Prahlad\\Documents\\Columbia\\Coursework\\Financing and Structuring for Data Science\\Project\\USO_ETF_Day_Trading\\uso_etf_venv\\Lib\\site-packages\\xgboost\\core.py:160: UserWarning: [17:24:26] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0750514818a16474a-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:742: \n",
      "Parameters: { \"max_features\", \"min_samples_leaf\", \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "best_model_low_xg, low_delta_pred_xg, df_list_xg = preprocess_and_predict(df, \"Low\", regressor=xgb.XGBRegressor(), param_dist=param_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment #4: Neural Network Regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low\n",
      "Close\n",
      "Adj Close\n",
      "High_DXY\n",
      "Low_DXY\n",
      "Close_DXY\n",
      "Adj Close_DXY\n",
      "High_CHF\n",
      "Low_CHF\n",
      "High_BNO\n",
      "Low_BNO\n",
      "Close_BNO\n",
      "Adj Close_BNO\n",
      "High_GSCI\n",
      "Low_GSCI\n",
      "High_USL\n",
      "Low_USL\n",
      "Close_USL\n",
      "Adj Close_USL\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Prahlad\\Documents\\Columbia\\Coursework\\Financing and Structuring for Data Science\\Project\\USO_ETF_Day_Trading\\uso_etf_venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:990: RuntimeWarning: overflow encountered in square\n",
      "  (array - array_means[:, np.newaxis]) ** 2, axis=1, weights=weights\n",
      "c:\\Users\\Prahlad\\Documents\\Columbia\\Coursework\\Financing and Structuring for Data Science\\Project\\USO_ETF_Day_Trading\\uso_etf_venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'regressor__solver': 'sgd', 'regressor__max_iter': 200, 'regressor__learning_rate_init': 0.01, 'regressor__learning_rate': 'adaptive', 'regressor__hidden_layer_sizes': (50, 50), 'regressor__alpha': 0.01, 'regressor__activation': 'logistic'}\n",
      "Mean Squared Error: 9.128672218718945\n",
      "R2 score: 0.27848957401402274\n",
      "Train Mean Squared Error: 9.7835403679447\n",
      "Train R2 score: 0.36999278816383774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Prahlad\\Documents\\Columbia\\Coursework\\Financing and Structuring for Data Science\\Project\\USO_ETF_Day_Trading\\uso_etf_venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for random search\n",
    "\n",
    "param_dist = {\n",
    "    'regressor__hidden_layer_sizes': [(50, 50), (100, 50, 25), (200, 100, 50)],\n",
    "    'regressor__activation': ['relu', 'tanh', 'logistic'],\n",
    "    'regressor__solver': ['adam', 'sgd'],\n",
    "    'regressor__alpha': [0.0001, 0.001, 0.01],\n",
    "    'regressor__learning_rate': ['constant', 'adaptive'],\n",
    "    'regressor__learning_rate_init': [0.001, 0.01, 0.1],\n",
    "    'regressor__max_iter': [200, 300, 400]\n",
    "}\n",
    "\n",
    "best_model_nn, high_delta_pred_nn, df_list_nn = preprocess_and_predict(df, \"High\", regressor=MLPRegressor(random_state=42), param_dist=param_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High\n",
      "Close\n",
      "Adj Close\n",
      "High_DXY\n",
      "Low_DXY\n",
      "Close_DXY\n",
      "Adj Close_DXY\n",
      "High_CHF\n",
      "Low_CHF\n",
      "High_BNO\n",
      "Low_BNO\n",
      "Close_BNO\n",
      "Adj Close_BNO\n",
      "High_GSCI\n",
      "Low_GSCI\n",
      "High_USL\n",
      "Low_USL\n",
      "Close_USL\n",
      "Adj Close_USL\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Prahlad\\Documents\\Columbia\\Coursework\\Financing and Structuring for Data Science\\Project\\USO_ETF_Day_Trading\\uso_etf_venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:990: RuntimeWarning: overflow encountered in square\n",
      "  (array - array_means[:, np.newaxis]) ** 2, axis=1, weights=weights\n",
      "c:\\Users\\Prahlad\\Documents\\Columbia\\Coursework\\Financing and Structuring for Data Science\\Project\\USO_ETF_Day_Trading\\uso_etf_venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'regressor__solver': 'sgd', 'regressor__max_iter': 200, 'regressor__learning_rate_init': 0.01, 'regressor__learning_rate': 'adaptive', 'regressor__hidden_layer_sizes': (50, 50), 'regressor__alpha': 0.01, 'regressor__activation': 'logistic'}\n",
      "Mean Squared Error: 8.763454310017995\n",
      "R2 score: 0.44850378543964387\n",
      "Train Mean Squared Error: 9.427883155032863\n",
      "Train R2 score: 0.4768410556544508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Prahlad\\Documents\\Columbia\\Coursework\\Financing and Structuring for Data Science\\Project\\USO_ETF_Day_Trading\\uso_etf_venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "best_model_low_nn, low_delta_pred_nn, df_list_nn = preprocess_and_predict(df, \"Low\", regressor=MLPRegressor(random_state=42), param_dist=param_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taking Predictions from the Best Model and Saving Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The best model is Linear Regression!\n",
    "data_train = df[df.index.isin(df_list_lr[\"X_train\"].index)]\n",
    "data_val = df[df.index.isin(df_list_lr[\"X_val\"].index)]\n",
    "data_test = df[df.index.isin(df_list_lr[\"X_test\"].index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>T10Y2Y_Ten_Two</th>\n",
       "      <th>Date_lag_Ten_Two</th>\n",
       "      <th>...</th>\n",
       "      <th>Close_USL</th>\n",
       "      <th>Adj Close_USL</th>\n",
       "      <th>Volume_USL</th>\n",
       "      <th>Date_lag_USL</th>\n",
       "      <th>Open_lag_USL</th>\n",
       "      <th>High_lag_USL</th>\n",
       "      <th>Low_lag_USL</th>\n",
       "      <th>Close_lag_USL</th>\n",
       "      <th>Adj Close_lag_USL</th>\n",
       "      <th>Volume_lag_USL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2006-04-10 00:00:00</td>\n",
       "      <td>546.000000</td>\n",
       "      <td>548.000000</td>\n",
       "      <td>541.359985</td>\n",
       "      <td>544.159973</td>\n",
       "      <td>544.159973</td>\n",
       "      <td>484738</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1 days 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2006-04-11 00:00:00</td>\n",
       "      <td>546.559998</td>\n",
       "      <td>547.119995</td>\n",
       "      <td>538.400024</td>\n",
       "      <td>545.599976</td>\n",
       "      <td>545.599976</td>\n",
       "      <td>162138</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3 days 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2006-04-12 00:00:00</td>\n",
       "      <td>545.760010</td>\n",
       "      <td>550.479980</td>\n",
       "      <td>542.479980</td>\n",
       "      <td>542.719971</td>\n",
       "      <td>542.719971</td>\n",
       "      <td>156038</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1 days 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2006-04-17 00:00:00</td>\n",
       "      <td>553.599976</td>\n",
       "      <td>559.200012</td>\n",
       "      <td>549.440002</td>\n",
       "      <td>558.320007</td>\n",
       "      <td>558.320007</td>\n",
       "      <td>114713</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1 days 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2006-04-18 00:00:00</td>\n",
       "      <td>560.799988</td>\n",
       "      <td>568.400024</td>\n",
       "      <td>556.559998</td>\n",
       "      <td>566.000000</td>\n",
       "      <td>566.000000</td>\n",
       "      <td>115338</td>\n",
       "      <td>0.15</td>\n",
       "      <td>3 days 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4412</th>\n",
       "      <td>4412</td>\n",
       "      <td>2023-10-19 00:00:00</td>\n",
       "      <td>79.370003</td>\n",
       "      <td>81.750000</td>\n",
       "      <td>78.940002</td>\n",
       "      <td>81.680000</td>\n",
       "      <td>81.680000</td>\n",
       "      <td>5924400</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>1 days 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>40.799999</td>\n",
       "      <td>40.799999</td>\n",
       "      <td>4300.0</td>\n",
       "      <td>1 days 00:00:00</td>\n",
       "      <td>0.689998</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>0.880002</td>\n",
       "      <td>0.480004</td>\n",
       "      <td>0.480004</td>\n",
       "      <td>17200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4413</th>\n",
       "      <td>4413</td>\n",
       "      <td>2023-10-20 00:00:00</td>\n",
       "      <td>81.589996</td>\n",
       "      <td>81.980003</td>\n",
       "      <td>80.169998</td>\n",
       "      <td>80.699997</td>\n",
       "      <td>80.699997</td>\n",
       "      <td>4660500</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>1 days 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>40.330002</td>\n",
       "      <td>40.330002</td>\n",
       "      <td>6200.0</td>\n",
       "      <td>1 days 00:00:00</td>\n",
       "      <td>-0.049999</td>\n",
       "      <td>0.509998</td>\n",
       "      <td>-0.009999</td>\n",
       "      <td>0.649997</td>\n",
       "      <td>0.649997</td>\n",
       "      <td>-19900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4414</th>\n",
       "      <td>4414</td>\n",
       "      <td>2023-10-23 00:00:00</td>\n",
       "      <td>80.220001</td>\n",
       "      <td>80.269997</td>\n",
       "      <td>78.349998</td>\n",
       "      <td>78.889999</td>\n",
       "      <td>78.889999</td>\n",
       "      <td>4607100</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>1 days 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>39.689999</td>\n",
       "      <td>39.689999</td>\n",
       "      <td>29300.0</td>\n",
       "      <td>1 days 00:00:00</td>\n",
       "      <td>0.739998</td>\n",
       "      <td>0.040001</td>\n",
       "      <td>0.309998</td>\n",
       "      <td>-0.469997</td>\n",
       "      <td>-0.469997</td>\n",
       "      <td>1900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4415</th>\n",
       "      <td>4415</td>\n",
       "      <td>2023-10-24 00:00:00</td>\n",
       "      <td>78.040001</td>\n",
       "      <td>78.220001</td>\n",
       "      <td>76.309998</td>\n",
       "      <td>76.930000</td>\n",
       "      <td>76.930000</td>\n",
       "      <td>6629600</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>3 days 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>12600.0</td>\n",
       "      <td>3 days 00:00:00</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.560001</td>\n",
       "      <td>-0.779999</td>\n",
       "      <td>-0.640003</td>\n",
       "      <td>-0.640003</td>\n",
       "      <td>23100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4417</th>\n",
       "      <td>4417</td>\n",
       "      <td>2023-10-26 00:00:00</td>\n",
       "      <td>76.830002</td>\n",
       "      <td>77.589996</td>\n",
       "      <td>76.489998</td>\n",
       "      <td>76.889999</td>\n",
       "      <td>76.889999</td>\n",
       "      <td>3518500</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>1 days 00:00:00</td>\n",
       "      <td>...</td>\n",
       "      <td>39.040001</td>\n",
       "      <td>39.040001</td>\n",
       "      <td>75400.0</td>\n",
       "      <td>1 days 00:00:00</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>0.509998</td>\n",
       "      <td>-0.170002</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>55100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2485 rows Ã— 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                 Date        Open        High         Low  \\\n",
       "0              0  2006-04-10 00:00:00  546.000000  548.000000  541.359985   \n",
       "1              1  2006-04-11 00:00:00  546.559998  547.119995  538.400024   \n",
       "2              2  2006-04-12 00:00:00  545.760010  550.479980  542.479980   \n",
       "4              4  2006-04-17 00:00:00  553.599976  559.200012  549.440002   \n",
       "5              5  2006-04-18 00:00:00  560.799988  568.400024  556.559998   \n",
       "...          ...                  ...         ...         ...         ...   \n",
       "4412        4412  2023-10-19 00:00:00   79.370003   81.750000   78.940002   \n",
       "4413        4413  2023-10-20 00:00:00   81.589996   81.980003   80.169998   \n",
       "4414        4414  2023-10-23 00:00:00   80.220001   80.269997   78.349998   \n",
       "4415        4415  2023-10-24 00:00:00   78.040001   78.220001   76.309998   \n",
       "4417        4417  2023-10-26 00:00:00   76.830002   77.589996   76.489998   \n",
       "\n",
       "           Close   Adj Close   Volume T10Y2Y_Ten_Two Date_lag_Ten_Two  ...  \\\n",
       "0     544.159973  544.159973   484738           0.08  1 days 00:00:00  ...   \n",
       "1     545.599976  545.599976   162138           0.05  3 days 00:00:00  ...   \n",
       "2     542.719971  542.719971   156038           0.07  1 days 00:00:00  ...   \n",
       "4     558.320007  558.320007   114713            0.1  1 days 00:00:00  ...   \n",
       "5     566.000000  566.000000   115338           0.15  3 days 00:00:00  ...   \n",
       "...          ...         ...      ...            ...              ...  ...   \n",
       "4412   81.680000   81.680000  5924400          -0.16  1 days 00:00:00  ...   \n",
       "4413   80.699997   80.699997  4660500          -0.14  1 days 00:00:00  ...   \n",
       "4414   78.889999   78.889999  4607100          -0.19  1 days 00:00:00  ...   \n",
       "4415   76.930000   76.930000  6629600          -0.19  3 days 00:00:00  ...   \n",
       "4417   76.889999   76.889999  3518500          -0.16  1 days 00:00:00  ...   \n",
       "\n",
       "      Close_USL  Adj Close_USL  Volume_USL     Date_lag_USL  Open_lag_USL  \\\n",
       "0      0.000000       0.000000         0.0                0      0.000000   \n",
       "1      0.000000       0.000000         0.0                0      0.000000   \n",
       "2      0.000000       0.000000         0.0                0      0.000000   \n",
       "4      0.000000       0.000000         0.0                0      0.000000   \n",
       "5      0.000000       0.000000         0.0                0      0.000000   \n",
       "...         ...            ...         ...              ...           ...   \n",
       "4412  40.799999      40.799999      4300.0  1 days 00:00:00      0.689998   \n",
       "4413  40.330002      40.330002      6200.0  1 days 00:00:00     -0.049999   \n",
       "4414  39.689999      39.689999     29300.0  1 days 00:00:00      0.739998   \n",
       "4415  39.000000      39.000000     12600.0  3 days 00:00:00     -0.500000   \n",
       "4417  39.040001      39.040001     75400.0  1 days 00:00:00     -0.300000   \n",
       "\n",
       "      High_lag_USL Low_lag_USL  Close_lag_USL  Adj Close_lag_USL  \\\n",
       "0         0.000000    0.000000       0.000000           0.000000   \n",
       "1         0.000000    0.000000       0.000000           0.000000   \n",
       "2         0.000000    0.000000       0.000000           0.000000   \n",
       "4         0.000000    0.000000       0.000000           0.000000   \n",
       "5         0.000000    0.000000       0.000000           0.000000   \n",
       "...            ...         ...            ...                ...   \n",
       "4412      0.590000    0.880002       0.480004           0.480004   \n",
       "4413      0.509998   -0.009999       0.649997           0.649997   \n",
       "4414      0.040001    0.309998      -0.469997          -0.469997   \n",
       "4415     -0.560001   -0.779999      -0.640003          -0.640003   \n",
       "4417      0.509998   -0.170002       0.730000           0.730000   \n",
       "\n",
       "      Volume_lag_USL  \n",
       "0                0.0  \n",
       "1                0.0  \n",
       "2                0.0  \n",
       "4                0.0  \n",
       "5                0.0  \n",
       "...              ...  \n",
       "4412         17200.0  \n",
       "4413        -19900.0  \n",
       "4414          1900.0  \n",
       "4415         23100.0  \n",
       "4417         55100.0  \n",
       "\n",
       "[2485 rows x 76 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prahlad\\AppData\\Local\\Temp\\ipykernel_49132\\1743431567.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_train[\"pred_high_open\"] = best_model_lr.predict(df_list_lr[\"X_train\"])\n",
      "C:\\Users\\Prahlad\\AppData\\Local\\Temp\\ipykernel_49132\\1743431567.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_train[\"actual_high_open\"] = data_train[\"High\"] - data_train[\"Open\"]\n",
      "C:\\Users\\Prahlad\\AppData\\Local\\Temp\\ipykernel_49132\\1743431567.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_train[\"pred_low_open\"] = best_model_low_lr.predict(df_list_lr[\"X_train\"])\n",
      "C:\\Users\\Prahlad\\AppData\\Local\\Temp\\ipykernel_49132\\1743431567.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_train[\"actual_low_open\"] = data_train[\"Low\"] - data_train[\"Open\"]\n",
      "C:\\Users\\Prahlad\\AppData\\Local\\Temp\\ipykernel_49132\\1743431567.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_val[\"pred_high_open\"] = best_model_lr.predict(df_list_lr[\"X_val\"])\n",
      "C:\\Users\\Prahlad\\AppData\\Local\\Temp\\ipykernel_49132\\1743431567.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_val[\"actual_high_open\"] = data_val[\"High\"] - data_val[\"Open\"]\n",
      "C:\\Users\\Prahlad\\AppData\\Local\\Temp\\ipykernel_49132\\1743431567.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_val[\"pred_low_open\"] = best_model_low_lr.predict(df_list_lr[\"X_val\"])\n",
      "C:\\Users\\Prahlad\\AppData\\Local\\Temp\\ipykernel_49132\\1743431567.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_val[\"actual_low_open\"] = data_val[\"Low\"] - data_val[\"Open\"]\n",
      "C:\\Users\\Prahlad\\AppData\\Local\\Temp\\ipykernel_49132\\1743431567.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_test[\"pred_high_open\"] = best_model_lr.predict(df_list_lr[\"X_test\"])\n",
      "C:\\Users\\Prahlad\\AppData\\Local\\Temp\\ipykernel_49132\\1743431567.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_test[\"actual_high_open\"] = data_test[\"High\"] - data_test[\"Open\"]\n",
      "C:\\Users\\Prahlad\\AppData\\Local\\Temp\\ipykernel_49132\\1743431567.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_test[\"pred_low_open\"] = best_model_low_lr.predict(df_list_lr[\"X_test\"])\n",
      "C:\\Users\\Prahlad\\AppData\\Local\\Temp\\ipykernel_49132\\1743431567.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_test[\"actual_low_open\"] = data_test[\"Low\"] - data_test[\"Open\"]\n"
     ]
    }
   ],
   "source": [
    "data_train[\"pred_high_open\"] = best_model_lr.predict(df_list_lr[\"X_train\"])\n",
    "data_train[\"actual_high_open\"] = data_train[\"High\"] - data_train[\"Open\"]\n",
    "data_train[\"pred_low_open\"] = best_model_low_lr.predict(df_list_lr[\"X_train\"])\n",
    "data_train[\"actual_low_open\"] = data_train[\"Low\"] - data_train[\"Open\"]\n",
    "\n",
    "\n",
    "data_val[\"pred_high_open\"] = best_model_lr.predict(df_list_lr[\"X_val\"])\n",
    "data_val[\"actual_high_open\"] = data_val[\"High\"] - data_val[\"Open\"]\n",
    "data_val[\"pred_low_open\"] = best_model_low_lr.predict(df_list_lr[\"X_val\"])\n",
    "data_val[\"actual_low_open\"] = data_val[\"Low\"] - data_val[\"Open\"]\n",
    "\n",
    "data_test[\"pred_high_open\"] = best_model_lr.predict(df_list_lr[\"X_test\"])\n",
    "data_test[\"actual_high_open\"] = data_test[\"High\"] - data_test[\"Open\"]\n",
    "data_test[\"pred_low_open\"] = best_model_low_lr.predict(df_list_lr[\"X_test\"])\n",
    "data_test[\"actual_low_open\"] = data_test[\"Low\"] - data_test[\"Open\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.to_csv('../data/data_train.csv')\n",
    "data_val.to_csv('../data/data_val.csv')\n",
    "data_test.to_csv('../data/data_test.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uso_etf_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
